{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/WISDM_ar_v1.1_raw.txt', header=None, names=['user', 'label', 'timestamp', 'x', 'y', 'z'], comment=';')\n",
    "df = df.sort_values('timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sampling rate to use\n",
    "SAMPLING_RATE = 20.0\n",
    "\n",
    "# Window length to use for classification (Samples @ 10 Hz)\n",
    "WINDOW_LENGTH = 100 \n",
    "\n",
    "# Stride length to use between windows (decrease to increase dataset size)\n",
    "WINDOW_STRIDE = WINDOW_LENGTH * 5\n",
    "\n",
    "# Mapping from label index to label name\n",
    "IDX_TO_LABELS = df.label.unique()\n",
    "\n",
    "# Mapping from label name to label index\n",
    "LABELS_TO_IDX = {label:idx for idx, label in enumerate(IDX_TO_LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import sliding_window, split_user_df\n",
    "from preprocessing import resample_df\n",
    "\n",
    "# Split the label DataFrame per user\n",
    "users = df.groupby(('label', 'user'))\n",
    "\n",
    "wdws = []\n",
    "y = []\n",
    "ids = []\n",
    "for (label, user), user_df in users:\n",
    "    \n",
    "    # Split the user DataFrame per recording session\n",
    "    splits = split_user_df(user_df)\n",
    "    \n",
    "    for split_df in splits:\n",
    "\n",
    "        # Calculate the timestamp index in seconds\n",
    "        ts =(split_df.timestamp - split_df.timestamp.iloc[0]) / 1e9\n",
    "\n",
    "        if ts.iloc[-1] < 10:\n",
    "            # Skip sessions that are smaller than 10 seconds\n",
    "            continue\n",
    "            \n",
    "        # Resample the DataFrame to SAMPLING_RATE\n",
    "        split_df = resample_df(split_df, SAMPLING_RATE)\n",
    "        \n",
    "        # Calculate sliding windows\n",
    "        for i in xrange(0, len(split_df) - WINDOW_LENGTH, WINDOW_STRIDE):\n",
    "            wdws.append(split_df.iloc[i:i+WINDOW_LENGTH])\n",
    "            y.append(LABELS_TO_IDX[label])\n",
    "            ids.append(int(user))\n",
    "         \n",
    "        \n",
    "y = np.asarray(y)\n",
    "ids = np.asarray(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.94756666   9.83376178   1.96037768 ...,  22.65071688  26.13949369\n",
      "   16.31421252]\n",
      " [ -9.07360324   5.3971892    0.85419209 ...,  10.72742887  10.12632582\n",
      "    6.74348333]\n",
      " [ -1.02057069  10.47345634   0.67809816 ...,  26.05866087  28.80690794\n",
      "   20.13279743]\n",
      " ..., \n",
      " [ -0.90319545   9.82867235   0.88664508 ...,   3.33021924  13.93921096\n",
      "   10.35672702]\n",
      " [ -0.93429949   9.83544171   0.66518208 ...,   3.86085447   6.84415106\n",
      "   44.91921498]\n",
      " [ -0.75940726   9.92661364   0.65113962 ...,  19.7930209   10.2231491\n",
      "    8.94319117]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "\n",
    "DATA_COLUMNS = ['x', 'y', 'z']\n",
    "\n",
    "X = []\n",
    "\n",
    "for wdw_df in wdws:\n",
    "    # Calculate PCA for window\n",
    "    pca_values = PCA(len(DATA_COLUMNS)).fit_transform(wdw_df.loc[:, DATA_COLUMNS].fillna(0))\n",
    "    pca_wdw_df = pd.DataFrame(pca_values, columns=DATA_COLUMNS)\n",
    "    \n",
    "    # calculate FFT for axis X\n",
    "    ffts_x = np.abs(np.fft.fft(pca_wdw_df.x.values))\n",
    "    ffts_x = ffts_x[1:ffts_x.shape[-1]/2 + 1]\n",
    "    \n",
    "    #calculate the mean of the amplitudes of the vectors\n",
    "    vector_ampli = 0.0\n",
    "    x=0.0\n",
    "    y=0.0\n",
    "    z=0.0\n",
    "\n",
    "    \n",
    "    for i in range(0,len(wdw_df.index)):\n",
    "              #print('-------------')\n",
    "              #print(i)\n",
    "              x1 = wdw_df.x.iloc[i]**2\n",
    "              #print(x)\n",
    "              y1 = wdw_df.y.iloc[i]**2\n",
    "              #print(y)\n",
    "              z1= wdw_df.z.iloc[i]**2\n",
    "              #print(z)\n",
    "              vector_ampli1= math.sqrt(x1+y1+z1)\n",
    "              vector_ampli += vector_ampli1\n",
    "              \n",
    "              #print('---')\n",
    "              #print(vector_ampli)\n",
    "\n",
    "              #print(vector_ampli1)\n",
    "              #print(vector_ampli)\n",
    "          \n",
    "    \n",
    "    vector_ampli_mean=np.float64(vector_ampli/(len(wdw_df.index)))\n",
    "    \n",
    "    \n",
    "    # Calculate features #wdws is a list of dataframes. \n",
    "    features = np.array([\n",
    "        wdw_df.x.mean(), # Orientation features\n",
    "        wdw_df.y.mean(), # Orientation features\n",
    "        wdw_df.z.mean(), # Orientation features\n",
    "        \n",
    "        #1\n",
    "        #wdw_df.x.std(),\n",
    "        #wdw_df.y.std(),\n",
    "        #wdw_df.z.std(),\n",
    "        \n",
    "        #2\n",
    "        vector_ampli_mean,\n",
    "        \n",
    "        pca_wdw_df.x.std(),\n",
    "        pca_wdw_df.y.std(),\n",
    "        pca_wdw_df.z.std(),\n",
    "\n",
    "    ])\n",
    "    #print(type(wdw_df.x.mean()))\n",
    "    #print(type(vector_ampli_mean))\n",
    "    # Concatenate fft X with features\n",
    "    features = np.concatenate((features, ffts_x))\n",
    "    \n",
    "    X.append(features)\n",
    "    \n",
    "X = np.nan_to_num(np.asarray(X), 0)    \n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-d8d446894dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Determine train & test window indices for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Fix random values\n",
    "random.seed = 1234\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Create Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "\n",
    "# Apply cross validation on the users\n",
    "nr_folds = 5\n",
    "uniq_ids = np.unique(ids)\n",
    "kf = KFold(n_splits=nr_folds, shuffle=True)\n",
    "splits = kf.split(uniq_ids)\n",
    "    \n",
    "cm = np.zeros([len(LABELS_TO_IDX), len(LABELS_TO_IDX)])\n",
    "for fold, (train_idx, test_idx) in enumerate(splits):\n",
    "    # Determine train & test user indices for this fold\n",
    "    train_idx = np.in1d(ids, uniq_ids[train_idx])\n",
    "    test_idx = np.in1d(ids, uniq_ids[test_idx])\n",
    "\n",
    "    # Determine train & test window indices for this fold\n",
    "    train_X, train_y = X[train_idx], y[train_idx]\n",
    "    test_X, test_y = X[test_idx], y[test_idx]\n",
    "\n",
    "    # Train the model on train set\n",
    "    model.fit(train_X, train_y)\n",
    "\n",
    "    # Perform prediction on test set\n",
    "    pred_y = model.predict(test_X)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm += confusion_matrix(y_true=test_y, y_pred=pred_y)\n",
    "\n",
    "\n",
    "# Calculate the mean of the Confusion Matrix\n",
    "cm = cm / np.float(nr_folds)\n",
    "\n",
    "# normalize Confusion matrix to 1 per class\n",
    "cm = cm / np.sum(cm, axis=1).reshape(-1, 1).astype(float)\n",
    "accuracy = cm.diagonal().sum() / len(cm)\n",
    "\n",
    "# convert Confusion Matrix to DataFrame\n",
    "cm = pd.DataFrame((100*cm).round(1))\n",
    "cm.columns = IDX_TO_LABELS\n",
    "cm.index = IDX_TO_LABELS\n",
    "\n",
    "print cm\n",
    "print\n",
    "print \"Accuracy: {}%\".format((accuracy * 100).round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
